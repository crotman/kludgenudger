---
title: "Nudging for less kludges: focusing on PMD alerts as possible kludges: open, fixed or new?"
author: "Bruno Crotman"
header-includes:
  - \usepackage{lscape}
  - \usepackage{smartdiagram}
  - \usesmartdiagramlibrary{additions}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}  
  - \definecolor{darkred}{RGB}{150, 40, 40}
  - \definecolor{darkgreen}{RGB}{30, 120, 30}
  - \definecolor{darkorange}{RGB}{40, 40, 160}
  - \newcommand{\comentario}[1]{}
output: 
    pdf_document:
        number_sections: true
        fig_caption: true
        toc: true
        toc_depth: 2 
        keep_tex:  true
        
bibliography: bib.bib


---



```{r setup, include=FALSE}

library(xml2)
library(tidyverse)
library(gt)
library(knitr)
library(kableExtra)
library(tidygraph)
library(ggraph)
library(patchwork)
library(magrittr)
library(scales)
library(magrittr)
library(patchwork)
library(feather)
library(ggrepel)

knitr::opts_chunk$set(echo = FALSE, size = "small", warning = FALSE, message = FALSE, cache = FALSE, fig.pos="H")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})




```



```{r definitions, echo=FALSE}

size_line_of_code <- 160

length_alert_name <- 35

length_alert_name_side_by_side <- 14

size_line_of_code_side_by_side <- 77


pmd_path <- "pmd/bin/pmd.bat"

rule_path <- "rulesets/java/quickstart.xml"

output_path <-  ""  

examples <- tribble(
    
    ~name,                  ~path,                                                              ~output,          
    "Versão Old Original",  "old" ,  "old_original",
    "Versão New 1",         "new",   "new_1"
    
) %>% 
    mutate(id = row_number())

```


\section{Introduction}\label{intro}

This document is part of a research project about software degradation
caused by careless developers' behavior and about strategies to deal
with such undesired behavior. These strategies will possibly be inspired
by concepts from game theory.

We assume that software degradation can be measured by the number and
the types of \textit{kludges} made by software developers in the code. 
A kludge is code that

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Partially fixes a bug or partially implements a feature.
\end{enumerate}

\setlength{\parindent}{1.2cm}
\hangindent=1.2cm
The term partial can be understood as in \textit{partial functions}. A
partial function is undefined for some elements in the formal domain.
For instance, the square root function restricted to the integers:
\(f(25)\) is defined, but \(f(26)\) is undefined. In terms of features,
we can think about a developer calculating the point on which two lines
cross and neglecting the case of parallel lines

\begin{enumerate}
\setcounter{enumi}{1}
\tightlist
\item
  The developer knows that the code is only a partial solution, with
  high probability. \footnote{We need to study technical debt papers
  to enrich the conceptual background.}
\end{enumerate}

This project aims to study how software projects evolve in terms of number
and kinds of kludges. So far, we are trying to identify kludges by looking 
at alerts generated by the PMD source code analyzer. PMD is static source 
code analyzer that is commonly used to find possible programming flaws. PMD is a good choice for a researcher to analyze bad practices, because it supports multiple languages and it's very flexible. It allows the researcher to provide his own rules for finding interesting patterns in a source code in Java or other languages.
These are the planned steps for this research project:


\begin{itemize}
\item
  Confirm the assumption that the frequency of PMD alerts is an accurate
  measure of the prevalence of kludges;
  
\item
  Confirm the assumption that kludges harm software development;

\item
  Confirm the assumption that there is a game in which, in Nash
  equilibrium, a developer chooses a strategy in which he gets personal
  benefits while causing harm to the project, by making kludges;

\item
  If all these assumptions are true, use mechanism design to devise how
  we can change the environment in a way that developers do not choose
  to make so much kludge, increasing the quality of the project in the
  long run.

\item
  Implement this mechanism building a plugin for a prominent CI tool,
  such as Travis or Jenkins or GitLab.
\end{itemize}


In this document, we evaluate PMD Source Code Alerts as proxies for kludges. In section \ref{pmd}, we present PMD Source Code Analyzer and show how we use the tool to generate alerts that are possible kludges. We use this tool, also, to create a simplified AST that will help us in the algorithm that infers now many new alerts were created, how many were fixed and how many remain open in a transition from an old version to a new version. This algorithm is described in Section \ref{alg}. In Section ref{results}, we compare the creation of new alerts with the creation of new Self Admitted Technical Debt (SATD) comments.   


% =========================================================
%
% PMD SOURCE CODE ANALYZER
%
% =========================================================

\section{The PMD Source Code Analyzer}\label{pmd}

We use PMD to list the alerts that represent \textit{possible kludges} in a source code. PMD receives a source code as input and generates a list of bad programming practices contained in the code, i.e., the alerts. The process we follow to generate the alerts using PMD source code analyzer is discussed in Section \ref{history}.


PMD traverses the AST of a source code searching for violations of rules
which are configured by the user. PMD comes with a default rule set for
the Java programming language. The default rule set finds common
programming flaws such as unused variables, empty catch blocks,
unnecessary object creation, and so forth. It is possible to configure a
different set of rules by creating a custom XML file. In the source code, we can see a simple code and the alerts
that were generated by the default rule set of PMD alerts. In this example, PMD generates two alerts of the type ControlStatementBraces (CSB), in lines 11 and 20. This alerts means that there are no braces in a statement that is inside a control statement.



```{r, cache=TRUE}

saida_alg2 <- kludgenudger::calculate_features_from_versions(
  code_file_old = "little-tree/code.java",
  code_file_new = "little-tree-new/code.java",
  pmd_path = pmd_path,
  glue_string = "{.data$id_alert}:line:{.data$beginline},\n{.data$small_rule}.{if_else(is.na(.data$rule_alert),'',paste0('\n',.data$rule_alert))}",
  mostra_new = c(2, 3, 4, 16),
  mostra_old =  c(2, 3, 5, 14, 12),
  blockrules_location = "data/blockrules/blockrules_simple.xml",
  optimize_feature_calculation = FALSE
)  


```


```{java code old simple, code=kludgenudger::read_and_decorate_code_and_alerts("little-tree/code.java",   saida_alg2$versions_executed$pmd_output[[1]], FALSE, 10, use_mnemonic = TRUE ), echo = TRUE }

```


\subsection{Using PMD to capture the history of alerts}\label{history}

To evaluate how the number of alerts evolved throughout the history of a
software project, we must be able to analyze a pair of different versions of a
source code (an old and a new version) and categorize each alert
contained in the code as either \textbf{new}, \textbf{fixed} or
\textbf{open}.

We define a PMD alert generated for the old version as either
\textbf{open} or \textbf{fixed} in the new version. An \textbf{open}
alert remains in the new version of the code. A \textbf{fixed} alert
does not exist in the new version.

A PMD alert generated for the new version is either \textbf{open} or
\textbf{new}. An \textbf{open} alert indicates that the same alert was
identified in the old version of the source code. A \textbf{new} alert
implies that the same alert cannot be identified in the old version.

The intersection between \textbf{fixed} alerts, \textbf{new} alerts and
\textbf{open} alerts is empty. The alerts identified as \textbf{open}
are equivalent in both new and old versions. To decide whether an alert
is \textbf{open}, \textbf{fixed} or \textbf{new}, one has to identify if
this alert in the old version is equivalent to its occurrence in the new
version. This document describes an algorithm to make this classification. 
At this point, we use the default rule set to generate the alerts.


\subsection{Using PMD to generate an simplified Abstract Syntax Tree }\label{ast}

In order to be able to categorize alerts in \textbf{new}, \textbf{open} and \textbf{fixed}, we could match the lines of the old version to the lines of the new version, using a diff functionality. Diff is useful but is not sufficient. Frequently, the source code changes are more complex than the ones we could address by using only diff. An alert $o$ in the old version could be essentially the same as the alert $n$ contained in the new version, but the piece of code where $o$ resides could be moved in a way that it´s impossible to match $o$ and $n$ only using information from diff. Despite that, we can use extra information that does not come directly from diff. The extra information used by the algorithm described in Section \ref{alg} comes from a simplified AST that we create using PMD Source Code Analyzer. 

PMD traverses the source code visiting many different kinds of elements. 
We do not use all the types of nodes recognized by PMD Alert to generate the simplified AST because there are many kinds 
of nodes that are not used in the algorithm described in Section\ref{alg}. If we used all the kinds of nodes, we would end up with a tree that would not add value to our analysis but would add complexity to our algorithm. The kinds of elements that were selected are listed below:
   
\begin{itemize}


\item \textbf{Block}: a block of statements enclosed by braces;

\item \textbf{ClassOrInterfaceBody}: the body of an interface or a class, excluding the declaration;

\item \textbf{CompilationUnit}: the root of an AST tree;

\item \textbf{Method}: a method, including body and declaration;

\item \textbf{Statement}: any statement, like an if statement or an assignment;

\end{itemize}

PMD is prepared to receive an optional XML file, along with the Source Code. This XML contain instructions about the alerts that must be generated by PMD. The default XML generates alerts when it finds common bad practices, but When we are recreating the simplified AST we are describing here, we pass to PMD an XML file with instructions to generate the all the nodes of the kinds we are interested in, which are listed above. The output from PMD lists these nodes and the location of these nodes in the Source Code as we can see in Table \ref{tab_nodes}. 

```{r, cache=TRUE}

saida_alg2$graph_old_with_alert %>% 
  as_tibble() %>% 
  select(
    `Kind of node` = rule,
    `Begin line` = beginline,
    `Begin column` = begincolumn,
    `End line` = endline,
    `End column` = endcolumn
  ) %>% 
  kable(
    caption = "Output from PMD when creating a simplified AST\\label{tab_nodes}"
  ) %>% 
  kable_styling(
    latex_options = c("striped", "hold_position")
  ) 
  


```




Looking at Table \ref{tab_nodes}, we see that there is information about the location of the nodes, in terms of lines and columns. We can infer which nodes are descendants of other nodes but we cannot see if the node is a child or a grandchild. We follow three steps to recreate the AST:

\begin{enumerate}
\item
  Link each element \(a\) to the set of elements \(X\) that are fully
  contained between the begin line / begin column and end line / end
  column of element \(a\). We can construct a directed graph in which
  the elements are the nodes and the links described are the edges. This
  is not a tree yet, because each node will have edges directed to all
  its descendants and not only its children in the AST.

\item
  Sort the nodes in the decreasing order of its number of children. The
  objective is to establish that, in a search through this graph, the
  first child chosen will be the one that is a child in the AST, and not
  only a descendant.

\item
  Proceed a deep-first search starting from the compilation unit node.
\end{enumerate}


\section{Research questions}
\label{as_whole}


\noindent
\textbf{RQ: Is the frequency of PMD Alerts an accurate measure of the prevalence of kludges?}
%\label{PMD_Kludge}

In a given transition between an old version and a new version we want to identify if there was an intense introduction of PMD Alerts. To do this we have to be able to categorize open, new and fixed PMD Alerts.

For each pair of an old and a new version of a source code, we can measure the intensity of possible kludge introduction occurred. This evidence of possible kludge introduction must be normalized by the size of the change in source code between the two versions. We do this by following this formula \footnote{Another possibility is to use this formula \[ \frac{\#NewAlerts - \#FixedAlerts}{Change}    \], where Change can be a measure based on the differences betwwen the versions}:

\[ \frac{\#NewAlerts - \#FixedAlerts}{\#NewAlerts + \#FixedAlerts}    \]


With these version transition measuredin terms of inclusion of PMD alerts, we can try to correlate of these events with some other evidence of kludge. In Section \ref{results} we calculate this correlation using Self Admitted Technical Debt (SATD) comments

Other evidence could be churns around the location of the event in subsequent commits. And this would be related with the statement 1 of the definition of kludge in Section \ref{as_whole}.

Other possible evidence could be survey and bag of words mining of issue, mailing lists, and commit messages showing evidence of kludge game. This could be related more with the Statement 2 of the definition of kludge in Section \ref{as_whole}.

\vspace{16px}
\noindent
\textbf{RQ: Do kludges harm software development?} \label{kludge_harm}

We need some way to measure degradation after a heavy introduction of
kludges. A drop in the popularity may not be a proper evidence. The
increment in the number of issues and bug fixed nor necessarily
represent a degradation. Churn could be used here.



% ========================================================= 
% % ALGORITHMS \% \%
%=========================================================

\section{Algorithm to categorize alerts}\label{alg}

This Section discusses the algorithm to categorize alerts as open, fixed or new.  The algorithm uses the simplified AST described in Section \ref{ast} to create features that help to infer if two alerts in different versions must be considered the same or not. We use the term feature as they are used in the field of statistical learning. In this field, the variables that are used to predict the outcome of an event are called \emph{independent variables}, \emph{predictors} or \emph{features}. The term \emph{feature} is used more appropriately when we are referring to a variable that is a composite one or more variables, or the result of a treatment upon the raw data. Given a pair of alerts, one from the old version and one from the new version, we use the mapping between the lines of the old and the new version and their ASTs as raw data to create the features that will be used to infer if if they are the same alert. At this moment we use an heuristic to infer if the pair of alerts is the same, as described in Section \ref{} 

\begin{center}
\smartdiagram[sequence diagram]{Get alerts for each version, Create AST for each version, Map new lines to old lines, Calculate features for each pair of new and old alert, Apply heuristics to features, Categorize alerts }
\end{center}


\subsection{An illustrative example}\label{source_used}

In this Section, we will consider the old and new version of a source
code as presented in Figure \ref{old_and_new_figure}. In the new version, the alert generated in
the line 11 of the old version was fixed.

```{java showing codes, code=kludgenudger::read_and_decorate_code_and_alerts_mapped("little-tree/code.java", saida_alg2$versions_executed$pmd_output[[1]], "little-tree-new/code.java", saida_alg2$versions_executed$pmd_output[[2]],saida_alg2$versions_crossed$lines_map[[1]], TRUE, 20, TRUE, 60), echo=TRUE, size="scriptsize"  }
```

![Source code used in the description of the algorithm](figures/fake.png)


\subsection{Get alerts for each version}

For the new and the old versions, we run PMD alerts using the default rule set as described Section \ref{history}. Table \ref{old_alerts} is created for the old version and Table \ref{new_alerts}, for the new version.


```{r , cache=TRUE}

saida_alg2$versions_executed$pmd_output[[1]] %>% 
  select(
    `Kind of node` = rule,
    `Begin line` = beginline,
    `Begin column` = begincolumn,
    `End line` = endline,
    `End column` = endcolumn
  ) %>% 
  kable(
    caption = "Old version's alerts\\label{old_alerts}"
  ) %>% 
  kable_styling(
    latex_options = c("striped", "HOLD_position")
  ) 



```

```{r , cache=TRUE}

saida_alg2$versions_executed$pmd_output[[2]] %>% 
  select(
    `Kind of node` = rule,
    `Begin line` = beginline,
    `Begin column` = begincolumn,
    `End line` = endline,
    `End column` = endcolumn
  ) %>% 
  kable(
    caption = "New version's alerts\\label{new_alerts}"
  ) %>% 
  kable_styling(
    latex_options = c("striped", "HOLD_position")
  ) 



```

\subsection{Create AST for each version}

For each version the algorithm creates a simplified AST as described in Section \ref{ast}. 

In Figure \ref{AST_compare_id_alerts} we can see the ASTs for the old
and the new versions. We can see the kind of nodes and the PMD alert if
there is one. In this figures, the numbers in the nodes are meaningless
and are presented only for reference.


```{r, echo=FALSE, message=FALSE, warning=FALSE,  out.width="100%", fig.width=12, fig.height=12, fig.cap="Abstract Syntax Trees. New and old versions, with alerts \\label{AST_compare_id_alerts}", fig.pos="H", cache=TRUE}

chart_graph_new <- kludgenudger::show_ast(
  saida_alg2$graph_new_with_alert,
  size_label = 3,
  show_label = TRUE,
  alpha_label = "mostra",
  name_field = "glue",
  aspect = 0.5
  
)

chart_graph_old <- kludgenudger::show_ast(
  saida_alg2$graph_old_with_alert,
  size_label = 3,
  show_label = "TRUE",
  alpha_label = "mostra",
  name_field = "glue",
  aspect = 0.5
  
)



chart_graph_old / chart_graph_new



```


\subsection{Map new lines to old lines}\label{map}

For each difference stated in the output of git diff (the sections of the diff file
starting with ``@@''), there is an indication of the number of lines
removed from the old version and the number of lines added to the new
one. The line in which the lines are removed from the old version and
the line at which the lines are added is indicated, too.\\
By using this information we create a relation between the lines of the
old version and the equivalent lines in the new version. For the new and
old versions presented in Section \ref{source_used}, the relation is shown in
Table \ref{table_map}.


```{r showing map , cache=TRUE }
saida_alg2$versions_crossed$lines_map[[1]] %>% 
  ungroup() %>% 
  mutate(
    row = row_number(),
    na_mark = if_else(is.na(map_remove) | is.na(map_add), row , NA_integer_  ),
    next_na = na_mark,
    last_na = na_mark
  ) %>% 
  fill(
    next_na, .direction = "up"
  ) %>% 
  fill(
    last_na, .direction = "down"
  ) %>% 
  replace_na(
    list(
      last_na = 0,
      next_na = nrow(saida_alg2$versions_crossed$lines_map[[1]]) + 1
    )
  ) %>%
  mutate(
    dist_next = next_na - row,
    dist_last = row - last_na + 0.1
  ) %>%
  rowwise() %>% 
  mutate(
    min_dist = min(dist_next, dist_last)
  ) %>% 
  filter(
    min_dist < 4
  ) %>%
  ungroup() %>% 
  mutate(    
    map_remove = 
      case_when(
        min_dist == 3.1 ~ str_glue("{lag(map_remove)+1}-"),
        min_dist == 3.0 ~ str_glue("-{lead(map_remove)-1}"),
        TRUE ~ map_remove %>% as.character()
      ),
    map_add = 
      case_when(
        min_dist == 3.1 ~ str_glue("{lag(map_add)+1}-"),
        min_dist == 3.0 ~ str_glue("-{lead(map_add)-1}"),
        TRUE ~ map_add %>% as.character()
      )
  ) %>% 
  select(old = map_remove, new = map_add) %>% 
  mutate(  
    old = if_else(is.na(old), str_glue("\\textcolor{{white}}{{{row_number()}}}"), old),
    new = if_else(is.na(new), str_glue("\\textcolor{{white}}{{{row_number()}}}"), new)
  ) %>% 
  pivot_wider(
    names_from = old,
    values_from = new,
    names_repair = "minimal"
  ) %>% 
  kable(
    caption = "Relation between lines of the old version and lines of the new version\\label{table_map}",
    escape = FALSE
  ) %>% 
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )
```


\subsection{Calculate features for each pair of new and old alert}


In the case of the source code we are using as an example, we calculate features for $2 \cdot 1 = 2$ combinations of new and old alerts, since we have 2 old alerts and 1 new alert. The combinations for which the features must be calculated are shown in Table \ref{combination}


```{r, cache=TRUE}

old_alerts <-  saida_alg2$versions_executed$pmd_output[[1]] %>%
  select(
    `Begin Line Old` = beginline,
    # `End Line Old` = endline,
    `Rule Old` = rule
  )

new_alerts <-  saida_alg2$versions_executed$pmd_output[[2]] %>%
  select(
    `Begin Line New` = beginline,
    # `End Line New` = endline,
    `Rule New` = rule
  )

combinations <- old_alerts %>%
  crossing(new_alerts)

combinations %>%
  kable(
    caption = "Combinations of new and old alerts for which the features must be calculated \\label{combination}",
    escape = FALSE,
    col.names = 
  ) %>%
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )



```


We propose the following list of features to calculated for each combination:


\subsubsection{Same Rule}

  A boolean indicator that tells if the alerts are of the  same type


\subsubsection{Same Group ID}\label{same_group}

  A boolean indicator that tells if the alerts are equivalent in terms of begin line and end line, considering the line map described in Section \ref{map}. 
  
  For each combination, Table \ref{same_group} shows the begin line in the old version, the corresponding begin line in the new version and the begin line in the new version \footnote{we suppress the end lines because for all alerts the begin lines and the old lines are the same}. We can see that the alert that begins in line 20 of the old version corresponds to the alert that begins in line 2 of the new version, so, for this combination the feature "Same group" is true. For the other combination, the feature "Same Group" is false. 
  
  
```{r , cache=TRUE}

map_lines <- saida_alg2$versions_crossed$lines_map[[1]] %>% 
  select(
    map_line_old = map_remove,
    map_line_new = map_add
  )

map_old <- map_lines %>% rename(`Corresponding line in new version` =  map_line_new)

combinations %>% 
  left_join(
    map_old,
    by = c("Begin Line Old"="map_line_old")
  ) %>% 
  select(
    `Begin Line Old`,
    `Rule Old`,
    `Corresponding line in new version`,
    `Begin Line New`,
    `Rule New`
  ) %>% 
  mutate(
    `Same group` = `Corresponding line in new version` == `Begin Line New`
  ) %>% 
  kable(
    caption = "Same group feature \\label{same_group}",
    escape = FALSE,
    col.names = 
      c(
        "Begin Line Old",
        "Rule Old",
        "Corresponding line\n in new version",
        "Begin Line New",
        "Rule New",
        "Same group"
      ) %>% linebreak()
  ) %>%
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )










```
  
\subsubsection {Same Method Group ID} \label{same_method_group_id}

  A boolean indicator that tells if the alerts belong to methods that are in the same group in the sense of the "same group" feature we describe in Section \ref{same_group}. 
  
  First we find alert's method following the path from the alert´s node to the root. The first node of the kind "method" or "constructor" found in this path defines the alert's method. Considering the example we are following, in Figure \ref{path_node_to_root_1} we can see the ASTs for the first combination of alerts (see Table \ref{combination} ). In this combination the method of the old alert is in node 5 and the method for the new alert is in node 4. Table \ref{tab_same_method} shows that the begin and end lines of the alert in the old version do not correspond to the lines in the new version. The correspondence uses the map defined in the Section \ref{map}. For this combination, the feature Same Method Group ID is FALSE.
  
  
  
  
```{r, echo=FALSE, message=FALSE, warning=FALSE,  out.width="100%", fig.width=10, fig.height=10, fig.cap="Abstract Syntax Tree. Nodes with the same number are equivalent \\label{path_node_to_root_1}", fig.pos="H" , cache=TRUE}


path_old <- kludgenudger::show_ast(
  saida_alg2$graphs_from_alerts_old %>%  rename( id_alert = id_alert_old, graph = graph_old) %$% graph[[1]] , 
  size_label = 3,
  aspect = 4,
  nudge_x = 0.5,
  title = "Path from alert in old version, \nin line 11, to root"
)

path_new <- kludgenudger::show_ast(
  saida_alg2$graphs_from_alerts_new %>%  rename( id_alert = id_alert_new, graph = graph_new) %$% graph[[1]] , 
  size_label = 3,
  aspect = 4,
  nudge_x = 0.5,
  title = "Path from alert in old version, \nin line 22, to root"
)


(path_old + plot_spacer() + path_new)


```

```{r}

tribble(
  ~"-",  ~"Old version", ~"New version",
  "Begin line", 8, 19,
  "End line", 15, 27
) %>% 
  left_join(
    map_lines,
    by = c("Old version" = "map_line_old")
  ) %>% 
  select(
    `-`,
    `Old version`,
    `Corresponding line in the new version` = map_line_new,
    `New version`
  ) %>% 
    kable(
    caption = "Defining if Same Method Group ID \\label{tab_same_method}",
    escape = FALSE,
    col.names = 
      c(
        "-",
        "Old version",
        "Corresponding line\nin the new version",
        "New version"
      ) %>% linebreak()
  ) %>%
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )




```


In Figure \ref{path_node_to_root_2} we can see the ASTs for the second combination of alerts (see Table \ref{combination} ). In this combination the method of the old alert is in node 3 and the method for the new alert is in node 4. Table \ref{tab_same_method_2} shows that the begin and end lines of the alert in the old version do correspond to the lines in the new version. The correspondence uses the map defined in the Section \ref{map}. For this combination, the feature Same Method Group ID is TRUE.


```{r, echo=FALSE, message=FALSE, warning=FALSE,  out.width="100%", fig.width=10, fig.height=10, fig.cap="Abstract Syntax Tree. Nodes with the same number are equivalent \\label{path_node_to_root_2}", fig.pos="H" , cache=TRUE}


path_old <- kludgenudger::show_ast(
  saida_alg2$graphs_from_alerts_old %>%  rename( id_alert = id_alert_old, graph = graph_old) %$% graph[[2]] , 
  size_label = 3,
  aspect = 4,
  nudge_x = 0.5,
  title = "Path from alert in old version, \nin line 20, to root"
)

path_new <- kludgenudger::show_ast(
  saida_alg2$graphs_from_alerts_new %>%  rename( id_alert = id_alert_new, graph = graph_new) %$% graph[[1]] , 
  size_label = 3,
  aspect = 4,
  nudge_x = 0.5,
  title = "Path from alert in old version, \nin line 22, to root"
)


(path_old + plot_spacer() + path_new)


```



```{r, cache=TRUE}

tribble(
  ~"-",  ~"Old version", ~"New version",
  "Begin line", 17, 19,
  "End line", 25, 27
) %>%  
  left_join(
    map_lines,
    by = c("Old version" = "map_line_old")
  ) %>% 
  select(
    `-`,
    `Old version`,
    `Corresponding line in the new version` = map_line_new,
    `New version`
  ) %>% 
    kable(
    caption = "Defining if Same Method Group ID \\label{tab_same_method_2}",
    escape = FALSE,
    col.names = 
      c(
        "-",
        "Old version",
        "Corresponding line\nin the new version",
        "New version"
      ) %>% linebreak()
  ) %>%
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )




```


\subsubsection {Same Method Name}

A boolean indicator that tells if the alerts were found in a method with the same name. The methods for the alerts are found the way described in Section \ref{same_method_group_id}, using the path from the node where the alerts is to the root of the AST. Instead of the corresponding lines, this feature evaluates the name of the methods. If the method related to the old alerts and the method related to the new alert are the same (even if the begin and end lines are not corresponding), then the feature is TRUE.


\subsubsection {Same Method Block}

A boolean indicator that shows if the alerts belong to the same block. The blocks are defined in a similar way than we do in Section \ref{same_method_group_id}, following the path from the node where each alert is until we find a node of one of this kinds: "block", "method" or "constructor". Then, the begin and end lines of the old alert and the corresponding lines in the new version are compared with the begin and end lines of the new alert, the same way we do in Section \ref{same_method_group_id}.

\subsubsection {Same Code}

For this feature we compare the source code that is contained in the nodes related to the alerts. 

\subsubsection {Same Method Code}

For this feature we compare the source codes of the methods related to the alerts. The methods related to the alerts are found the way we describe in Section \ref{same_method_group_id}, following the path on the AST from the node related to the alert to the root.

\subsubsection {Line distance}\label{line_distance}

Line distance is the distance between the "mean line" ($\frac{beginline + endline}{2}$) of the new alert and the "corresponding mean line" of the old alert. Table \ref{tab_line_distance} shows the line distance for the combinations of new and old alerts of the example we are following.

```{r}

old_alerts_ld <-  saida_alg2$versions_executed$pmd_output[[1]] %>%
  select(
    `Begin Line Old` = beginline,
    `End Line Old` = endline,
    `Rule Old` = rule
  ) 

new_alerts_ld <-  saida_alg2$versions_executed$pmd_output[[2]] %>%
  select(
    `Begin Line New` = beginline,
    `End Line New` = endline,
    `Rule New` = rule
  )

combinations_ld <- old_alerts_ld %>%
  crossing(new_alerts_ld)

map_lines <- saida_alg2$versions_crossed$lines_map[[1]] %>% 
  select(
    map_line_old = map_remove,
    map_line_new = map_add
  )

map_old_begin <- map_lines %>% rename(`Corresponding begin line in new version` =  map_line_new)
map_old_end <- map_lines %>% rename(`Corresponding end line in new version` =  map_line_new)


combinations_ld  %>% 
  left_join(
    map_old_begin,
    by = c("Begin Line Old"="map_line_old")
  ) %>% 
  left_join(
    map_old_end,
    by = c("End Line Old"="map_line_old")
  ) %>% 
  select(
    `Begin Line Old`,
    `End Line Old`,
    `Corresponding begin line in new version`,
    `Corresponding end line in new version`,
    `Begin Line New`,
    `End Line New`
  ) %>% 
  mutate(
    `Corresponding mean line` =  (`Corresponding begin line in new version` + `Corresponding end line in new version`) / 2,
    `Mean line of new alert` = (`Begin Line New` + `End Line New`) / 2,
    `Line distance` = abs(`Corresponding mean line` - `Mean line of new alert`)
  ) %>% 
  kable(
    caption = "Line distance feature \\label{tab_line_distance}",
    escape = FALSE,
    col.names = 
      c(
        "Begin Line\nOld",
        "End Line\nOld",
        "Corresponding\nbegin line\nin new version",
        "Corresponding\nend line\nin new version",
        "Begin Line\nNew",
        "End Line\nNew",
        "Corresponding\nmean line",
        "Mean line of\nnew alert",
        "Line distance"
      ) %>% linebreak()
  ) %>%
  kable_styling(
    font_size = ,
    latex_options = c("scale_down", "HOLD_position")
  )




```



Table \ref{table_features} shows the combinations \((n,o)\) in the
example. There are \(2 \cdot 1 = 2\) combinations whereas we have two
alerts in the old version and one alert in the new one.


```{r, cache=TRUE}

MUDOU <-  TRUE

kludgenudger::report_features(saida_alg2, "Resulting features\\label{table_features} ")



  # types_to_show = c(
  #   "same_rule",
  #   "same_id_group",
  #   "same_method_group",
  #   "same_method_name",
  #   "same_block",
  #   "same_code",
  #   "same_method_code",
  #   "dist_line",
  #   "dist_line_normalized_block",
  #   "dist_line_normalized_method",
  #   "dist_line_normalized_unit"
  # )

  
```


\subsection{Heuristic to decide based on the features}\label{heuristic}


The heuristic chosen in this work follow these rules when :

\begin{itemize}
\item If all the boolean features are TRUE and **Line Distance** is true, then the new and old alerts are declared the same and open;
\item If **Same Method Code** is TRUE, then we consider it's the same method, even if the name or the group is not the same. But if the method code is the same, then the alert code and the kind of the alert must be the same. So if the features **Same Rule**, **Same Method Code** and 
**Same Code** are TRUE, then the new and old alerts are declared the same and open;
\end{itemize}


 
<!-- 924 -->
<!-- \begin{itemize} -->

<!-- 925 -->
<!-- \item If all the boolean features are TRUE and **Line Distance** is true, then the new and old alerts are declared the same and open; -->

<!-- 926 -->
<!-- \item If **Same Method Code** is TRUE, then we consider it's the same method, even if the name or the group is not the same. But if the method code is the same, then the alert code and the kind of the alert must be the same. So if the features **Same Rule**, **Same Method Code** and  -->

<!-- 927 -->
<!-- **Same Code** are TRUE, then the new and old alerts are declared the same and open; -->

<!-- 928 -->
<!-- \item If it is the same id_group, then they are mapped to the same lines.  -->

<!-- 929 -->
<!-- If this happens, the kind of alert is the same and one of the features about the method is the same, then the new and old alerts are declared the same and open.  -->

<!-- 930 -->
<!-- The features about the method are all; -->

<!-- 931 -->
<!-- \end{itemize} -->



\section{Comparing new alerts with new SATD comments}\label{results}


In this section, we select some tagged versions of the project ArgoUML. 
For each pair of sequential versions, we generate the PMD Alerts and categorise them in New, Fixed and Open using the algorithm described in Section \ref{alg}.
We want to understand if the amount of new alerts, normalized by the magnitude of the overall change between two versions, is a good proxy for the amount of kludge introduced in the code base. 
A first approach we try in this preliminary investigation is to measure the correlation between the normalized amount of new alerts and comments that indicate Self Admitted Technical Debt.

In @Potdar2014, the authors discuss that the existence of comments that contain some specific patterns may indicate what they call Self-Admitted Technical Debts (SATD). 
In @Sierra2019, Self-Admitted Technical Debt is defined as the event in which the developer consciously introduce debt. 
According to these two works, the developer acknowledges the SATD in the form of comments. 
In @Wehaibi2016 we can find some patterns based on the work of Potdar and Shihab. 
For instance, some of these patterns are "hack", "retarded", "remove this code", "treat this as a soft error", "kludge", "fixme", "this isn't quite right", "fix this crap", "abandon all hope" and "kaboom".
 

In this document, we selected some versions from the project ArgoUML and extracted the PMD alerts, using the the procedure described in Section \ref{alg}. Figure \ref{timeseries} shows three metrics related to the transitions of versions. 

In the first plot, "Change" tries to measure the amount of difference between versions, summing the module of the difference between the number of lines of code of new and old files: 

\begin{equation} \label{eq_change} \sum_{f \in files}{|\#LoC_{f, new} - \#LoC_{f, old}|} \end{equation}

The second plot shows the number of new and fixed alerts, as categorized by the algorithm in Section \ref{alg}.

The third plot shows the number of comments that contain expressions listed in @Wehaibi2016. We categorize each comment as new, fixed and open using a simple approach: if the text in the comment is the same, the comments are classified as "open", the other ones are classified as fixed, if they are in the old version and open if they are in the new version. 



```{r, cache=TRUE}

# 
# all_results <- read_rds("all_results.rds")
# 
# 
# categorised <- all_results %>%
#   mutate(data = map(.x = data, .f = function(x){x$categorised_alerts}  )) %>%
#   unnest(data) %>%
#   group_by(version_old, version_new) %>%
#   mutate(
#     id_file = row_number()
#   ) %>%
#   unnest(data)
# 
# versions_executed <- all_results %>%
#   mutate(data = map(.x = data, .f = function(x){x$versions_executed}  )) %>%
#   unnest(data) %>%
#   group_by(version_old, version_new) %>%
#   mutate(
#     id_file = row_number()
#   ) %>%
#   unnest(data)
# 
# write_rds(categorised, "categorised.rds")
# 
# write_rds(versions_executed, "versions_executed.rds")
# 
categorised <-  read_rds("categorised.rds")

versions_executed <-  read_rds("versions_executed.rds")

friction <- versions_executed %>% 
  mutate(friction = abs(lines_right - lines_left)) %>% 
  select(
    version_old,
    version_new,
    friction
  ) %>% 
  group_by(
    version_old,
    version_new
  ) %>% 
  summarise(
    friction = sum(friction)
  ) %>% 
  mutate(
    comparison = str_glue("{str_pad(version_old, width = 2, side = 'left', pad = '0')} to {version_new}")
  ) 



fixed_new_alerts <- categorised %>% 
  ungroup() %>% 
  select(
    version_old,
    version_new,
    category
  ) %>% 
  mutate(
    comparison = str_glue("{str_pad(version_old, width = 2, side = 'left', pad = '0')} to {version_new}")
  ) %>% 
  filter(
    category %in% c("fixed", "new")
  ) %>% 
  group_by(
    comparison,
    category
  ) %>% 
  summarise(
    n = n()
  ) %>% 
  mutate(
    category = str_to_title(category)
  )



total_alerts <- categorised %>% 
  ungroup() %>% 
  select(
    version_old,
    version_new,
    category
  ) %>% 
  filter(
    category %in% c("fixed", "new")
  ) %>% 
  mutate(
    comparison = str_glue("{str_pad(version_old, width = 2, side = 'left', pad = '0')} to {version_new}")
  ) %>% 
  group_by(
    comparison
  ) %>% 
  summarise(
    n = n()
  )



alerts_friction <- total_alerts %>% 
  inner_join(
    friction,
    by = c("comparison")
  )


# 
# satd_expressions <- c(
# "hack",
# "retarded",
# "at a loss",
# "stupid",
# "remove this code",
# "remove this",
# "ugly",
# "take care",
# "something's gone wrong",
# "something has gone wrong",
# "something gone wrong",
# "nuke",
# "is problematic",
# "problematic",
# "may cause problem",
# "hacky",
# "unknown why we ever experience this",
# "treat this as a soft error",
# "silly",
# "workaround for bug",
# "workaround",
# "kludge",
# "fixme",
# "this isn't quite right",
# "trial and error",
# "give up",
# "this is wrong",
# "hang our heads in shame",
# "temporary solution",
# "temporary fix",
# "causes issue",
# "something bad is going on",
# "cause for issue",
# "this doesn't look right",
# "this does not look right",
# "is this next line safe",
# "this indicates a more fundamental problem",
# "temporary crutch",
# "this can be a mess",
# "this isn't very solid",
# "this is temporary and will go away",
# "is this line really safe",
# "there is a problem",
# "some fatal error",
# "something serious is wrong",
# "don't use this",
# "do not use this",
# "get rid of this",
# "doubt that this would work",
# "this is bs",
# "give up and go away",
# "risk of this blowing up",
# "just abandon it",
# "prolly a bug",
# "buggy",
# "probably a bug",
# "hope everything will work",
# "toss it",
# "barf",
# "something bad happened",
# "fix this crap",
# "yuck",
# "certainly buggy",
# "remove me before production",
# "remove this before production",
# "you can be unhappy now",
# "this is uncool",
# "bail out",
# "it doesn't work yet",
# "it does not work yet",
# "crap",
# "inconsistency",
# "abandon all hope",
# "kaboom"
# )
# 
# satd_expressions <- str_glue("\\b{satd_expressions}\\b")
# 
# 
# acha_kludge <- function(x){
#   bateu <- str_match(string = x, pattern = satd_expressions)
#   bateu[!is.na(bateu)]
# }
# 
# 
# library(furrr)
# 
# plan(multiprocess)
# 
# # teste <- comments_18 %>%
# #   mutate(
# #     comment = str_to_lower(comment)
# #   ) %>%
# #   mutate(match = future_map(.x = comment, .f = acha_kludge, .progress = TRUE )) %>%
# #   unnest(match)
# 
# 
# comments_kludge <- list.files(path = "C:/doutorado/resultados", pattern = "rds", full.names =  TRUE ) %>%
#   enframe(
#     name = "id_version",
#     value = "file_version"
#   ) %>%
#   mutate(
#     comments = map(
#     .x = file_version,
#     .f = read_rds
#   )) %>%
#   unnest(comments) %>%
#   mutate(
#     comment = str_to_lower(comment)
#   ) %>%
#   mutate(match = furrr::future_map(.x = comment, .f = acha_kludge, .progress = TRUE )) %>%
#   unnest(match)
# 
# write_rds(comments_kludge, "comments_kludge.rds")


compare_comments  <- function(old, new){
  
  old <- old %>% 
    rename_with(
      ~str_glue("{.x}_old")
    )
  
  new <- new %>% 
    rename_with(
      ~str_glue("{.x}_new")
    )
  
  saida <- comments_comparison <- old %>% 
    full_join(new,
              by = c("comment_old" = "comment_new") )
  
  saida %>% 
    summarise(
      n_comments_new = id_comment_old %>% is.na() %>% sum(),
      n_comments_fixed = id_comment_new %>% is.na() %>% sum()
    )
  
}


comments_kludge <- read_rds("comments_kludge.rds") %>% 
  mutate(
    version = str_match(file_version, "[0-9]{2}_?[0-9]?")
  ) %>% 
  select(
    version,
    comment
  ) %>%
  mutate(
    version = str_replace(version, "09_", "9_")
  ) %>% 
  mutate(
    id_comment = row_number()
  ) %>% 
  group_by(
    version
  ) %>% 
  nest() %>% 
  ungroup() %>% 
  mutate(
    comments_old = lag(data)
  ) %>% 
  rename(
    comments_new = data
  ) %>% 
  mutate(
    comparison = str_glue("{lag(version)} to {version}")
  ) %>% 
  slice_tail(
    n = nrow(.) - 1
  ) %>% 
  mutate(
    comparison_comments = map2(.x = comments_old, .y = comments_new, .f = compare_comments  )
  ) %>% 
  select(
    comparison,
    comparison_comments
  ) %>% 
  unnest(comparison_comments)


comparisons <- fixed_new_alerts %>% 
  pivot_wider(
    names_from = category,
    values_from = n
  ) %>% 
  rename(
    n_fixed_alerts = Fixed,
    n_new_alerts = New
  ) %>% 
  left_join(
    total_alerts,
    by = c("comparison")
  ) %>% 
  rename(
    n_alerts = n
  ) %>% 
  left_join(
    friction,
    by = c("comparison")
  ) %>% 
  left_join(
    comments_kludge,
    by = c("comparison")
  ) %>% 
  mutate(
    n_comments = n_comments_new + n_comments_fixed,
    prop_new_alerts = n_new_alerts / n_alerts,
    prop_new_comments = n_comments_new / n_comments,
    prop_new_alerts_friction = (n_new_alerts - n_fixed_alerts)/friction ,
    prop_new_comments_friction = (n_comments_new - n_comments_fixed)/friction
  ) 


comparisons_tidy <- comparisons %>% 
  select(-c(version_new, version_old)) %>% 
  pivot_longer(
    cols = -comparison,
    names_to = "atribute",
    values_to = "value"
  ) %>% 
  mutate(
    comparison = str_replace_all(comparison, "9_", "09_")
  )



```



```{r, fig.asp= 1.75, fig.cap="\\label{timeseries}Changes, alerts and comments", fig.height=0.9, cache=TRUE }


fixed_new_data <- comparisons_tidy %>% 
  filter(atribute %in% c("n_fixed_alerts", "n_new_alerts")) %>% 
  mutate(
    category = if_else(atribute == "n_fixed_alerts", "Fixed", "New")
  )


ggplot_fixed_new <- ggplot(fixed_new_data,
    aes(
      x = comparison,
      y = value,
      color = category,
      group = category
    ) 
) +
  geom_line(
    size = 1.2
  ) +
  geom_point(
    size = 2.5
  ) +
  theme_minimal() +
  scale_color_manual(
    values = c(Fixed = "darkgreen", New = "darkred") 
  ) +
  theme(
   axis.text.x = element_text(angle = 90) ,
   legend.position = "top"
  ) +
  scale_y_continuous(
    labels = number_format(big.mark = ",")
  ) +
  ggtitle(
    "Number of fixed/new alerts per version transition"
  ) +
  labs(
    x = "Transition",
    y = "Number of alerts",
    color = "Category"
  )


changed <- comparisons_tidy %>% 
  filter(atribute %in% c("friction")) 

ggplot_changed <- ggplot(changed,
    aes(
      x = comparison,
      y = value,
      group = 1
    )
) +
  geom_line(
    size = 1.2,
    color = "darkblue"
  ) +
  geom_point(
    size = 2.5,
    color = "darkblue"
  ) +
  theme_minimal() +
  theme(
   axis.text.x = element_text(angle = 90) ,
   legend.position = "top"
  ) +
  scale_y_continuous(
    labels = number_format(big.mark = ",")
  ) +
  ggtitle(
    "Change per version transition"
  ) +
  labs(
    x = "Transition",
    y = "Change"
  )
                          


fixed_new_comments <- comparisons_tidy %>% 
  filter(atribute %in% c("n_comments_new", "n_comments_fixed")) %>% 
  mutate(
    category = if_else(atribute == "n_comments_fixed", "Fixed", "New")
  ) %>% 
  mutate(
    
  )


ggplot_fixed_new_comments <- ggplot(fixed_new_comments,
    aes(
      x = comparison,
      y = value,
      color = category,
      group = category
    ) 
) +
  geom_line(
    size = 1.2
  ) +
  geom_point(
    size = 2.5
  ) +
  theme_minimal() +
  scale_color_manual(
    values = c(Fixed = "darkgreen", New = "darkred") 
  ) +
  theme(
   axis.text.x = element_text(angle = 90) ,
   legend.position = "top"
  ) +
  scale_y_continuous(
    labels = number_format(big.mark = ",")
  ) +
  ggtitle(
    "Number of fixed/new comments per version transition"
  ) +
  labs(
    x = "Transition",
    y = "Number of comments",
    color = "Category"
  )


ggplot_changed / ggplot_fixed_new / ggplot_fixed_new_comments + plot_layout(heights = unit(c(5, 5, 5), c("cm", "cm", "cm") ), widths = unit(c(15, 15, 15), c("cm", "cm", "cm") ))



```

\newpage 


We try to measure if there is a correlation between the amount of new alerts and the amount of new comments.

Figure \ref{scatter_prop} shows the relation between the proportion of new alerts and the proportion of new comments:

$$PropNewAlerts = \frac{NewAlerts}{NewAlerts + OldAlerts}$$


$$PropNewComments = \frac{NewComments}{NewComments + OldComments}$$

We can see that there is a positive correlation.


```{r fig.cap="\\label{scatter_prop}Proportion of new alerts x Proportion of new comments", fig.pos="H", cache=TRUE}


ggplot(
  comparisons %>% filter(friction > 1000),
  aes(
    x = prop_new_comments,
    y = prop_new_alerts,
  )
  ) +
  geom_point( aes(size = friction)) +
  geom_text_repel(aes(label = comparison), nudge_y = 0.05, size = 2) +
  geom_smooth(method = "lm") +
  ggtitle(
    "Proportion of new comments x Proportion of new alerts"
  ) +
  labs(
    x = "Proportion of new comments",
    y = "Proportion of new alerts",
    size = "Change"
  ) +
  scale_x_continuous(
    label = percent_format()
  ) +
  scale_y_continuous(
    label = percent_format()
  ) +
  scale_size_continuous(
    label = number_format(big.mark = ",", accuracy = 1)
  ) +
  theme_minimal() +
  theme(
    legend.position = "top"
  ) +
  NULL

```
  

In Figure \ref{scatter_diff} we correlate two metrics based on the difference between the number of alerts and comments normalized by the amount of change:

$$DiffNewAlerts = \frac{NewAlerts - OldAlerts}{Change}$$

$$DiffNewComments = \frac{NewComments - OldComments}{Change}$$

Where Change is calculated as in Equation \ref{eq_change}.

We can see that there is a positive correlation too.


```{r  fig.cap="\\label{scatter_diff}Proportion of new alerts x Proportion of new comments", fig.pos="H", cache=TRUE}

ggplot(
  comparisons %>% filter(friction > 1000),
  aes(
    x = prop_new_comments_friction,
    y = prop_new_alerts_friction,
  )
  ) +
  geom_point( aes(size = friction)) +
  geom_text_repel(aes(label = comparison), nudge_y = 0.05, size = 2) +
  geom_smooth(method = "lm") +
  ggtitle(
    "Normalized difference: comments x alerts"
  ) +
  labs(
    x = "Normalized difference between old and new comments",
    y = "Normalized difference between old and new alerts",
    size = "Change"
  ) +
  scale_x_continuous(
    label = percent_format()
  ) +
  scale_y_continuous(
    label = percent_format()
  ) +
  scale_size_continuous(
    label = number_format(big.mark = ",", accuracy = 1)
  ) +
  theme_minimal() +
  theme(
    legend.position = "top"
  ) +
  NULL




```


It´s necessary to verify if the positive correlation that we found is statistically significant. Table \ref{tab_reg} shows the results of these regressions. In the form:

$$ NewAlertsProportion = \alpha + \beta NewCommentsProportions $$

and

$$ AlertsNormalizedDifferences = \alpha + \beta AlertsNormalizedDifferences $$



As we can see by the P-Value of the betas, we cannot reject the null hypothesis in which there is no relation between comments and alerts.




```{r, cache=TRUE}

library(parsnip)
library(gtsummary)

lm_prop <-  linear_reg() %>% 
  set_engine("lm")

lm_prop_fit <- lm_prop %>% 
  fit(prop_new_alerts ~ prop_new_comments, data = comparisons %>% filter(friction > 1000))

lm_prop_friction <-  linear_reg() %>% 
  set_engine("lm")

lm_prop_fit_friction <- lm_prop %>% 
  fit(prop_new_alerts_friction ~ prop_new_comments_friction, data = comparisons %>% filter(friction > 1000))


tbl_prop <- tbl_regression(
  lm_prop_fit$fit,
  pvalue_fun = function(x) style_pvalue(x, digits = 2),
  label = prop_new_comments ~ "New Comments Proportion",
  intercept = TRUE
) 

tbl_norm <- tbl_regression(
  lm_prop_fit_friction$fit,
  pvalue_fun = function(x) style_pvalue(x, digits = 2),
  label = prop_new_comments_friction ~ "Comments Norm. Difference",
  intercept = TRUE
) 

tbl_final <- tbl_merge(
  list(tbl_prop, tbl_norm),
  tab_spanner = c("New Alerts Proportions","Alerts Norm. Differences")
)


tbl_final %>% 
  as_kable_extra(caption = "\\label{tab_reg} Regression: alerts on comments")




```


In order to be able to reject the null hypothesis and accept that there is a correlation between comments and alerts, we must run the same procedures for more versions of the project and for more projects. We can refine the way we select the comments, too. There are papers that use more sofisticated schemes to identify SATD comments. These can be our next steps. 



\section{References}













